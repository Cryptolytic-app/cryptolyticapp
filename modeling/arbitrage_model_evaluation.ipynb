{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptolytic Arbitrage Model Evaluation and Selection\n",
    "\n",
    "This notebook contains the code and analysis to select models with the best performance for the Cryptolytic project. You can find more information on data processing in this [notebook](https://github.com/Cryptolytic-app/cryptolytic/blob/master/modeling/arbitrage_data_processing.ipynb) and modeling in this [notebook](https://github.com/Cryptolytic-app/cryptolytic/blob/master/modeling/arbitrage_modeling.ipynb).\n",
    "\n",
    "#### Background on Arbitrage Models\n",
    "Arbitrage models were created with the goal of predicting arbitrage 10 min before it happens in an active crypto market. The models are generated by getting all of the combinations of 2 exchanges that support the same trading pair, engineering technical analysis features, merging that data on 'closing_time', engineering more features, and creating a target that signals an arbitrage opportunity. Arbitrage signals predicted by the model have a direction indicating which direction the arbitrage occurs in. A valid arbitrage signal is when the arbitrage lasts >30 mins because it takes time to move coins from one exchange to the other in order to successfully complete the arbitrage trades.\n",
    "\n",
    "The models predict whether there will be an arbitrage opportunity that starts 10 mins after the prediction time and lasts for at least 30 mins, giving a user enough times to execute trades.\n",
    "\n",
    "More than 6000+ iterations of models were generated in this notebook and the best ones were selected from each possible arbitrage combination based on model selection criteria outlined later in this section. The models were Random Forest Classifier and the best model parameters varied for each dataset. The data was obtained from the respective exchanges via their api, and we did a 70/30 train/test split on 5 min candlestick data that fell anywhere in the range from Jun 2015 - Oct 2019. There was a 2 week gap left between the train and test sets to prevent data leakage. The models return 0 (no arbitrage), 1 (arbitrage from exchange 1 to exchange 2) and -1 (arbitrage from exchange 2 to exchange 1). \n",
    "\n",
    "The profit calculation incorporated fees like in the real world. We used mean percent profit as the profitability metric which represented the average percent profit per arbitrage trade if one were to act on all trades predicted by the model in the testing period, whether those predictions were correct or not.\n",
    "\n",
    "#### Model Evaluation Criteria\n",
    "- ROC AUC score\n",
    "- Precison\n",
    "- Recall\n",
    "- F1 Score\n",
    "- Status\n",
    "- Profit\n",
    "\n",
    "\n",
    "\n",
    "#### Model Selection\n",
    "From the 6000+ iterations of models trained, the best models were narrowed down based on the following criteria:\n",
    "- How often the models predicted arbitrage when it didn't exist (False positives)\n",
    "- How many times the models predicted arbitrage correctly (True positives)\n",
    "- How profitable the model was in the real world over the period of the test set.\n",
    "\n",
    "#### Results and Discussion\n",
    "\n",
    "For each of the models, show a dataframe of the LR scores, default RF scores, and hyperparm tuned RF scores.\n",
    "\n",
    "\n",
    "There were 21 models that met the thresholds for model selection critera (details of these models can be found at the end of this nb). The final models were all profitable with gains anywhere from 0.2% - 2.3% within the varied testing time periods (Note: the model with >9% mean percent profit was an outlier). Visualizations for how these models performed can be viewed at https://github.com/Lambda-School-Labs/cryptolytic-ds/blob/master/finalized_notebooks/visualization/arb_performance_visualization.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "├── cryptolytic/                        <-- The top-level directory for all arbitrage work\n",
    "│   ├── modeling/                       <-- Directory for modeling work\n",
    "│   │      ├──data/                     <-- Directory with subdirectories containing 5 min candle data\n",
    "│   │      │   ├─ arb_data/             <-- Directory for csv files of arbitrage model training data\n",
    "│   │      │   │   └── *.csv\n",
    "│   │      │   │\n",
    "│   │      │   ├─ csv_data/             <-- Directory for csv files after combining datasets and FE pt.2\n",
    "│   │      │   │   └── *.csv\n",
    "│   │      │   │\n",
    "│   │      │   ├─ ta_data/              <-- Directory for csv files after FE pt.1 \n",
    "│   │      │   │   └── *.csv\n",
    "│   │      │   │\n",
    "│   │      │   ├─ *.zip                 <-- ZIP files of all of the data\n",
    "│   │      │   \n",
    "│   │      ├──final_models/             <-- Directory for final models after model selection\n",
    "│   │      │      └── *.pkl\n",
    "│   │      │\n",
    "│   │      ├──model_perf/               <-- Directory for performance csvs after training models\n",
    "│   │      │      └── *.json\n",
    "│   │      │\n",
    "│   │      ├──models/                   <-- Directory for all pickle models\n",
    "│   │      │      └── *.pkl\n",
    "│   │      │\n",
    "│   │      ├─arbitrage_data_processing.ipynb      <-- Notebook for data processing and creating csvs\n",
    "│   │      │\n",
    "│   │      ├─arbitrage_modeling.ipynb             <-- Notebook for baseline models and hyperparam tuning\n",
    "│   │      │\n",
    "│   │      ├─arbitrage_model_selection.ipynb      <-- Notebook for model selection\n",
    "│   │      │\n",
    "│   │      ├─arbitrage_model_evaluation.ipynb     <-- Notebook for final model evaluation\n",
    "│   │      │\n",
    "│   │      ├─environment.yml                      <-- yml file to create conda environment\n",
    "│   │      │\n",
    "│   │      ├─trade_recommender_models.ipynb       <-- Notebook for trade recommender models\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import itertools\n",
    "from zipfile import ZipFile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Models\n",
    "\n",
    "All the arbitrage datasets that will be used in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "arb_data_paths = glob.glob('data/arb_data/*.csv')\n",
    "print(len(arb_data_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_exchange_1</th>\n",
       "      <th>high_exchange_1</th>\n",
       "      <th>low_exchange_1</th>\n",
       "      <th>close_exchange_1</th>\n",
       "      <th>base_volume_exchange_1</th>\n",
       "      <th>nan_ohlcv_exchange_1</th>\n",
       "      <th>volume_adi_exchange_1</th>\n",
       "      <th>volume_obv_exchange_1</th>\n",
       "      <th>volume_cmf_exchange_1</th>\n",
       "      <th>volume_fi_exchange_1</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>higher_closing_price</th>\n",
       "      <th>pct_higher</th>\n",
       "      <th>arbitrage_opportunity</th>\n",
       "      <th>window_length</th>\n",
       "      <th>arbitrage_opportunity_shift</th>\n",
       "      <th>window_length_shift</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.29509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.910828</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.910828</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.910828</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.910828</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.910828</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   open_exchange_1  high_exchange_1  low_exchange_1  close_exchange_1  \\\n",
       "0           0.0063           0.0064          0.0063            0.0064   \n",
       "1           0.0064           0.0064          0.0064            0.0064   \n",
       "2           0.0064           0.0064          0.0064            0.0064   \n",
       "3           0.0064           0.0064          0.0064            0.0064   \n",
       "4           0.0064           0.0064          0.0064            0.0064   \n",
       "\n",
       "   base_volume_exchange_1  nan_ohlcv_exchange_1  volume_adi_exchange_1  \\\n",
       "0                    25.0                   0.0               26.29509   \n",
       "1                     5.0                   0.0               25.00000   \n",
       "2                     0.0                   1.0                0.00000   \n",
       "3                     0.0                   1.0                0.00000   \n",
       "4                     0.0                   1.0                0.00000   \n",
       "\n",
       "   volume_obv_exchange_1  volume_cmf_exchange_1  volume_fi_exchange_1  ...  \\\n",
       "0                    0.0               1.000000                   0.0  ...   \n",
       "1                    0.0               0.833333                   0.0  ...   \n",
       "2                    0.0               0.833333                  -0.0  ...   \n",
       "3                    0.0               0.833333                  -0.0  ...   \n",
       "4                    0.0               0.833333                   0.0  ...   \n",
       "\n",
       "   year  month  day  higher_closing_price  pct_higher  arbitrage_opportunity  \\\n",
       "0  2016      8   17                     1    1.910828                     -1   \n",
       "1  2016      8   17                     1    1.910828                     -1   \n",
       "2  2016      8   17                     1    1.910828                     -1   \n",
       "3  2016      8   17                     1    1.910828                     -1   \n",
       "4  2016      8   17                     1    1.910828                     -1   \n",
       "\n",
       "   window_length  arbitrage_opportunity_shift  window_length_shift  target  \n",
       "0              5                         -1.0                 40.0      -1  \n",
       "1             10                          0.0                  5.0       0  \n",
       "2             15                          0.0                 10.0       0  \n",
       "3             20                          0.0                 15.0       0  \n",
       "4             25                          0.0                 20.0       0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(arb_data_paths[1], index_col=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkls = glob.glob('models/*.pkl')\n",
    "len(pkls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['close_exchange_1','base_volume_exchange_1', \n",
    "            'nan_ohlcv_exchange_1','volume_adi_exchange_1', 'volume_obv_exchange_1',\n",
    "            'volume_cmf_exchange_1', 'volume_fi_exchange_1','volume_em_exchange_1', \n",
    "            'volume_vpt_exchange_1','volume_nvi_exchange_1', 'volatility_atr_exchange_1',\n",
    "            'volatility_bbhi_exchange_1','volatility_bbli_exchange_1', \n",
    "            'volatility_kchi_exchange_1', 'volatility_kcli_exchange_1',\n",
    "            'volatility_dchi_exchange_1','volatility_dcli_exchange_1',\n",
    "            'trend_macd_signal_exchange_1', 'trend_macd_diff_exchange_1', \n",
    "            'trend_adx_exchange_1', 'trend_adx_pos_exchange_1', \n",
    "            'trend_adx_neg_exchange_1', 'trend_vortex_ind_pos_exchange_1', \n",
    "            'trend_vortex_ind_neg_exchange_1', 'trend_vortex_diff_exchange_1', \n",
    "            'trend_trix_exchange_1', 'trend_mass_index_exchange_1', \n",
    "            'trend_cci_exchange_1', 'trend_dpo_exchange_1', 'trend_kst_sig_exchange_1',\n",
    "            'trend_kst_diff_exchange_1', 'trend_aroon_up_exchange_1',\n",
    "            'trend_aroon_down_exchange_1', 'trend_aroon_ind_exchange_1',\n",
    "            'momentum_rsi_exchange_1', 'momentum_mfi_exchange_1',\n",
    "            'momentum_tsi_exchange_1', 'momentum_uo_exchange_1',\n",
    "            'momentum_stoch_signal_exchange_1', 'momentum_wr_exchange_1', \n",
    "            'momentum_ao_exchange_1', 'others_dr_exchange_1', 'close_exchange_2',\n",
    "            'base_volume_exchange_2', 'nan_ohlcv_exchange_2',\n",
    "            'volume_adi_exchange_2', 'volume_obv_exchange_2',\n",
    "            'volume_cmf_exchange_2', 'volume_fi_exchange_2',\n",
    "            'volume_em_exchange_2', 'volume_vpt_exchange_2',\n",
    "            'volume_nvi_exchange_2', 'volatility_atr_exchange_2',\n",
    "            'volatility_bbhi_exchange_2', 'volatility_bbli_exchange_2',\n",
    "            'volatility_kchi_exchange_2', 'volatility_kcli_exchange_2',\n",
    "            'volatility_dchi_exchange_2', 'volatility_dcli_exchange_2',\n",
    "            'trend_macd_signal_exchange_2',\n",
    "            'trend_macd_diff_exchange_2', 'trend_adx_exchange_2',\n",
    "            'trend_adx_pos_exchange_2', 'trend_adx_neg_exchange_2',\n",
    "            'trend_vortex_ind_pos_exchange_2',\n",
    "            'trend_vortex_ind_neg_exchange_2',\n",
    "            'trend_vortex_diff_exchange_2', 'trend_trix_exchange_2',\n",
    "            'trend_mass_index_exchange_2', 'trend_cci_exchange_2',\n",
    "            'trend_dpo_exchange_2', 'trend_kst_sig_exchange_2',\n",
    "            'trend_kst_diff_exchange_2', 'trend_aroon_up_exchange_2',\n",
    "            'trend_aroon_down_exchange_2',\n",
    "            'trend_aroon_ind_exchange_2',\n",
    "            'momentum_rsi_exchange_2', 'momentum_mfi_exchange_2',\n",
    "            'momentum_tsi_exchange_2', 'momentum_uo_exchange_2',\n",
    "            'momentum_stoch_signal_exchange_2',\n",
    "            'momentum_wr_exchange_2', 'momentum_ao_exchange_2',\n",
    "            'others_dr_exchange_2', 'year', 'month', 'day',\n",
    "            'higher_closing_price', 'pct_higher', \n",
    "            'arbitrage_opportunity', 'window_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for calculating profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying arbitrage window length to target, in minutes\n",
    "interval = 30\n",
    "\n",
    "def get_higher_closing_price(df):\n",
    "    \"\"\"\n",
    "    Returns the exchange with the higher closing price\n",
    "    \"\"\"\n",
    "    # exchange 1 has higher closing price\n",
    "    if (df['close_exchange_1'] - df['close_exchange_2']) > 0:\n",
    "        return 1\n",
    "    \n",
    "    # exchange 2 has higher closing price\n",
    "    elif (df['close_exchange_1'] - df['close_exchange_2']) < 0:\n",
    "        return 2\n",
    "    \n",
    "    # closing prices are equivalent\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_close_shift(df, interval=interval):\n",
    "    \"\"\"\n",
    "    Shifts the closing prices by the selected interval +\n",
    "    10 mins.\n",
    "    \n",
    "    Returns a df with new features:\n",
    "    - close_exchange_1_shift\n",
    "    - close_exchange_2_shift\n",
    "    \"\"\"\n",
    "    \n",
    "    rows_to_shift = int(-1*(interval/5))\n",
    "    \n",
    "    df['close_exchange_1_shift'] = df['close_exchange_1'].shift(\n",
    "        rows_to_shift - 2)\n",
    "    \n",
    "    df['close_exchange_2_shift'] = df['close_exchange_2'].shift(\n",
    "        rows_to_shift - 2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_profit(df):\n",
    "    \"\"\"\n",
    "    Calculates the profit of an arbitrage trade.\n",
    "    \n",
    "    Returns df with new profit feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if exchange 1 has the higher closing price\n",
    "    if df['higher_closing_price'] == 1:\n",
    "        \n",
    "        # return how much money you would make if you bought \n",
    "        # on exchange 2, sold on exchange 1, and took account \n",
    "        # of 0.55% fees\n",
    "        return (((df['close_exchange_1_shift'] / \n",
    "                 df['close_exchange_2'])-1)*100)-.55\n",
    "    \n",
    "    # if exchange 2 has the higher closing price\n",
    "    elif df['higher_closing_price'] == 2:\n",
    "        \n",
    "        # return how much money you would make if you bought \n",
    "        # on exchange 1, sold on exchange 2, and took account \n",
    "        # of 0.55% fees\n",
    "        return (((df['close_exchange_2_shift'] / \n",
    "                 df['close_exchange_1'])-1)*100)-.55\n",
    "    \n",
    "    # if the closing prices are the same\n",
    "    else:\n",
    "        return 0 # no arbitrage\n",
    "\n",
    "def profit(X_test, y_preds):  \n",
    "    # creating dataframe from test set to calculate profitability\n",
    "    test_with_preds = X_test.copy()\n",
    "\n",
    "    # add column with higher closing price\n",
    "    test_with_preds['higher_closing_price'] = test_with_preds.apply(\n",
    "            get_higher_closing_price, axis=1)\n",
    "\n",
    "    # add column with shifted closing price\n",
    "    test_with_preds = get_close_shift(test_with_preds)\n",
    "\n",
    "    # adding column with predictions\n",
    "    test_with_preds['pred'] = y_preds\n",
    "\n",
    "    # adding column with profitability of predictions\n",
    "    test_with_preds['pct_profit'] = test_with_preds.apply(\n",
    "            get_profit, axis=1).shift(-2)\n",
    "\n",
    "    # filtering out rows where no arbitrage is predicted\n",
    "    test_with_preds = test_with_preds[test_with_preds['pred'] != 0]\n",
    "\n",
    "    # calculating mean profit where arbitrage predicted...\n",
    "    pct_profit_mean = round(test_with_preds['pct_profit'].mean(), 2)\n",
    "\n",
    "    # calculating median profit where arbitrage predicted...\n",
    "    pct_profit_median = round(test_with_preds['pct_profit'].median(), 2)\n",
    "    \n",
    "    return pct_profit_mean, pct_profit_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_n_params(pkl, filename):\n",
    "    \n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    \n",
    "    if pkl.split('.')[0][-2:] in ['rf', 'lr']:\n",
    "        params = {}\n",
    "        features = df.drop(\n",
    "            labels=['target', 'closing_time'], \n",
    "                axis=1).columns.to_list()\n",
    "        print(\"no feat\")\n",
    "\n",
    "    else:\n",
    "        params = pkl.split('/')[2].split('.')[0]\n",
    "        params = params.split('_')[-3:]\n",
    "        max_feat = params[0]\n",
    "        max_depth = params[1]\n",
    "        n_estimators = params[2]\n",
    "        params = {\n",
    "            'max_features': max_feat,\n",
    "            'max_depth': max_depth,\n",
    "            'n_estimators': n_estimators\n",
    "        }\n",
    "        features = df.drop(\n",
    "            labels=['target', 'closing_time'], \n",
    "                axis=1).columns.to_list()\n",
    "        # TODO: turn this into the .txt file\n",
    "    return df, features, params\n",
    "\n",
    "def tts(df, features):\n",
    "    '''\n",
    "    Retrieve CSV\n",
    "    Train/Test Split CSV\n",
    "    Returns:\n",
    "        X_train\n",
    "        X_test\n",
    "        y_train\n",
    "        y_test\n",
    "    \n",
    "    '''\n",
    "  \n",
    "    # change 'closing_time' to datetime\n",
    "    df['closing_time'] = pd.to_datetime(df['closing_time'])\n",
    "    \n",
    "    target = 'target'\n",
    "    \n",
    "    ## train test split\n",
    "    tt_split_row = round(len(df)*.82)\n",
    "    tt_split_time = df['closing_time'][tt_split_row]\n",
    "    cutoff_time = tt_split_time - dt.timedelta(days=14)\n",
    "\n",
    "    # train and test subsets\n",
    "    train = df[df['closing_time'] < cutoff_time]\n",
    "    test = df[df['closing_time'] > tt_split_time]\n",
    "\n",
    "    # X, y matrix\n",
    "    X_train = train[features]\n",
    "    X_test = test[features]\n",
    "    y_train = train[target]\n",
    "    y_test = test[target]\n",
    "    print(X_test.columns.to_list()[0])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def predictions(pkl, X_test, y_test):\n",
    "    \n",
    "    with open(pkl, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # make predictions\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "def confusion_feat(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # labels for confusion matrix\n",
    "    unique_y_test = y_test.unique().tolist()\n",
    "    unique_y_preds = list(set(y_preds))\n",
    "    labels = list(set(unique_y_test + unique_y_preds))\n",
    "    labels.sort()\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "\n",
    "    # create confusion matrix\n",
    "    conf_mat = pd.DataFrame(confusion_matrix(y_test, y_preds),\n",
    "                             columns=columns, index=index)\n",
    "#     print(model_name + ' confusion matrix:')\n",
    "    print(conf_mat, '\\n')\n",
    "    \n",
    "    # Some models never predicted -1, some never predicted 1, and \n",
    "    # some never predicted 1 or -1, meaning that they never predicted\n",
    "    # arbitrage at all. Each case needs to be handled with a conditional.\n",
    "    # confusion matrix has -1, 0, 1 predictions\n",
    "    if 'Predicted 1' in conf_mat.columns and 'Predicted -1' in conf_mat.columns:\n",
    "        # total number correct arbitrage preds (-1)\n",
    "        correct_arb_neg1 = conf_mat['Predicted -1'].loc[0]\n",
    "        # total number correct arbitrage preds (1)\n",
    "        correct_arb_1 = conf_mat['Predicted 1'].loc[2]\n",
    "        # total number correct arbitrage preds (-1) + (1)\n",
    "        correct_arb = correct_arb_neg1 + correct_arb_1\n",
    "\n",
    "    # confusion matrix has 0, 1 predictions\n",
    "    elif 'Predicted 1' in conf_mat.columns:\n",
    "        # total number correct arbitrage preds (-1)\n",
    "        correct_arb_neg1 = 0\n",
    "        # total number correct arbitrage preds (1)\n",
    "        correct_arb_1 = conf_mat['Predicted 1'].loc[1]\n",
    "        # total number correct arbitrage preds (-1) + (1)\n",
    "        correct_arb = correct_arb_neg1 + correct_arb_1\n",
    "\n",
    "\n",
    "    # confusion matrix has -1, 0 predictions\n",
    "    elif 'Predicted -1' in conf_mat.columns:\n",
    "        # total number correct arbitrage preds (-1)\n",
    "        correct_arb_neg1 = conf_mat['Predicted -1'].loc[0]\n",
    "        # total number correct arbitrage preds (1)\n",
    "        correct_arb_1 = 0\n",
    "        # total number correct arbitrage preds (-1) + (1)\n",
    "        correct_arb = correct_arb_neg1 + correct_arb_1\n",
    "\n",
    "\n",
    "    # confusion matrix has only 0\n",
    "    else:\n",
    "        correct_arb = 0\n",
    "    \n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no feat\n",
      "open_exchange_1\n",
      "             Predicted -1.0  Predicted 0.0  Predicted 1.0\n",
      "Actual -1.0               0            659              1\n",
      "Actual 0.0                0           6696              7\n",
      "Actual 1.0                0           6342              0 \n",
      "\n",
      "{'-1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 660}, '0.0': {'precision': 0.48886617507483393, 'recall': 0.9989556914814263, 'f1-score': 0.6564705882352943, 'support': 6703}, '1.0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6342}, 'accuracy': 0.48858080992338565, 'macro avg': {'precision': 0.1629553916916113, 'recall': 0.33298523049380874, 'f1-score': 0.21882352941176475, 'support': 13705}, 'weighted avg': {'precision': 0.23910032626972727, 'recall': 0.48858080992338565, 'f1-score': 0.3210742322467112, 'support': 13705}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       660\n",
      "         0.0       0.49      1.00      0.66      6703\n",
      "         1.0       0.00      0.00      0.00      6342\n",
      "\n",
      "    accuracy                           0.49     13705\n",
      "   macro avg       0.16      0.33      0.22     13705\n",
      "weighted avg       0.24      0.49      0.32     13705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def performance_metrics(pkls, features):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # instantiate performance df\n",
    "    columns = ['filename', 'model_id', 'parameters',\n",
    "                'accuracy_score', 'mean_pct_profit',\n",
    "                'precision', 'recall', 'f1_score',\n",
    "                'support', 'correct_arb_preds']\n",
    "    perf_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for pkl in pkls:\n",
    "        \n",
    "        # naming \n",
    "        file = '_'.join(pkl.split('/')[1].split('_')[:4])\n",
    "        filepath = f'data/arb_data/{file}.csv'\n",
    "        model_id = pkl.split('/')[1].split('.')[0]\n",
    "        \n",
    "        # if pkl file is rf or lf give it all features from df\n",
    "        df, features, params = feat_n_params(pkl, filepath)\n",
    "        \n",
    "        # train/test split and predict\n",
    "        X_train, X_test, y_train, y_test = tts(df, features)\n",
    "        y_preds = predictions(pkl, X_test, y_test)\n",
    "        \n",
    "        # stats\n",
    "        pct_prof_mean, pct_prof_median = profit(X_test, y_preds)\n",
    "        conf_mat = confusion_feat(y_test, y_preds)\n",
    "        print(classification_report(y_test, y_preds, output_dict=True))\n",
    "        print(classification_report(y_test, y_preds))\n",
    "\n",
    "        perf_dict = {\n",
    "            'filename': file,\n",
    "            'model_id': model_id,\n",
    "            'parameters': params,\n",
    "            'accuracy_score': 0,\n",
    "            'mean_pct_profit': pct_prof_mean,\n",
    "            'precision': 0,\n",
    "            'recall': 0,\n",
    "            'f1_score': 0,\n",
    "            'support': 0,\n",
    "            'correct_arb_preds': 0\n",
    "        }\n",
    "        perf_df = perf_df.append(perf_dict, ignore_index=True)\n",
    "    return perf_df, y_preds, y_test\n",
    "\n",
    "arb_data_paths = glob.glob('data/arb_data/*.csv')\n",
    "pkls = glob.glob('models/*.pkl')\n",
    "perf_df, y_preds, y_test = performance_metrics(pkls[:1], features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>model_id</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>mean_pct_profit</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "      <th>correct_arb_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cbpro_bitfinex_ltc_usd</td>\n",
       "      <td>cbpro_bitfinex_ltc_usd_lr</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename                   model_id parameters  \\\n",
       "0  cbpro_bitfinex_ltc_usd  cbpro_bitfinex_ltc_usd_lr         {}   \n",
       "\n",
       "  accuracy_score  mean_pct_profit precision recall f1_score support  \\\n",
       "0              0            -0.18         0      0        0       0   \n",
       "\n",
       "  correct_arb_preds  \n",
       "0                 0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptolytic-env",
   "language": "python",
   "name": "cryptolytic-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
