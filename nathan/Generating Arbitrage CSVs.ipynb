{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bitfinex_eos_usdt_300.csv', 'hitbtc_eos_usdt_300.csv'],\n",
       " ['bitfinex_bch_btc_300.csv', 'coinbase_pro_bch_btc_300.csv'],\n",
       " ['bitfinex_bch_btc_300.csv', 'hitbtc_bch_btc_300.csv'],\n",
       " ['bitfinex_etc_usd_300.csv', 'coinbase_pro_etc_usd_300.csv'],\n",
       " ['bitfinex_btc_usd_300.csv', 'coinbase_pro_btc_usd_300.csv'],\n",
       " ['bitfinex_ltc_btc_300.csv', 'coinbase_pro_ltc_btc_300.csv'],\n",
       " ['bitfinex_ltc_btc_300.csv', 'hitbtc_ltc_btc_300.csv'],\n",
       " ['bitfinex_dash_usd_300.csv', 'coinbase_pro_dash_usd_300.csv'],\n",
       " ['bitfinex_dash_btc_300.csv', 'coinbase_pro_dash_btc_300.csv'],\n",
       " ['bitfinex_dash_btc_300.csv', 'hitbtc_dash_btc_300.csv'],\n",
       " ['bitfinex_ltc_usd_300.csv', 'coinbase_pro_ltc_usd_300.csv'],\n",
       " ['bitfinex_bch_usdt_300.csv', 'hitbtc_bch_usdt_300.csv'],\n",
       " ['bitfinex_bch_usd_300.csv', 'coinbase_pro_bch_usd_300.csv'],\n",
       " ['bitfinex_eos_usd_300.csv', 'coinbase_pro_eos_usd_300.csv'],\n",
       " ['bitfinex_xrp_usd_300.csv', 'coinbase_pro_xrp_usd_300.csv'],\n",
       " ['bitfinex_eth_btc_300.csv', 'coinbase_pro_eth_btc_300.csv'],\n",
       " ['bitfinex_eth_btc_300.csv', 'hitbtc_eth_btc_300.csv'],\n",
       " ['bitfinex_eth_usdt_300.csv', 'hitbtc_eth_usdt_300.csv'],\n",
       " ['bitfinex_eth_usd_300.csv', 'coinbase_pro_eth_usd_300.csv'],\n",
       " ['bitfinex_ltc_usdt_300.csv', 'hitbtc_ltc_usdt_300.csv'],\n",
       " ['bitfinex_zrx_usd_300.csv', 'coinbase_pro_zrx_usd_300.csv'],\n",
       " ['bitfinex_xrp_btc_300.csv', 'coinbase_pro_xrp_btc_300.csv'],\n",
       " ['bitfinex_xrp_btc_300.csv', 'hitbtc_xrp_btc_300.csv'],\n",
       " ['bitfinex_eos_btc_300.csv', 'coinbase_pro_eos_btc_300.csv'],\n",
       " ['bitfinex_eos_btc_300.csv', 'hitbtc_eos_btc_300.csv'],\n",
       " ['bitfinex_btc_usdt_300.csv', 'hitbtc_btc_usdt_300.csv'],\n",
       " ['coinbase_pro_dash_btc_300.csv', 'hitbtc_dash_btc_300.csv'],\n",
       " ['coinbase_pro_eth_btc_300.csv', 'hitbtc_eth_btc_300.csv'],\n",
       " ['coinbase_pro_xrp_btc_300.csv', 'hitbtc_xrp_btc_300.csv'],\n",
       " ['coinbase_pro_eos_btc_300.csv', 'hitbtc_eos_btc_300.csv'],\n",
       " ['coinbase_pro_eth_usdc_300.csv', 'hitbtc_eth_usdc_300.csv'],\n",
       " ['coinbase_pro_bch_btc_300.csv', 'hitbtc_bch_btc_300.csv'],\n",
       " ['coinbase_pro_ltc_btc_300.csv', 'hitbtc_ltc_btc_300.csv'],\n",
       " ['coinbase_pro_btc_usdc_300.csv', 'hitbtc_btc_usdc_300.csv']]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_file_pairs(exchanges):\n",
    "    filenames = []\n",
    "    for directory in os.listdir('ohlcv_data'):\n",
    "        if directory != '.DS_Store':\n",
    "            for filename in os.listdir('ohlcv_data/' + directory):\n",
    "                if filename.endswith('300.csv'):\n",
    "                     filenames.append(filename)\n",
    "    file_pairs = []\n",
    "    for filename_1 in filenames:\n",
    "        remaining_filenames = filenames[filenames.index(filename_1)+1:]\n",
    "        for filename_2 in remaining_filenames:\n",
    "            for exchange in exchanges:\n",
    "                if filename_1.replace(exchange, '') in filename_2:\n",
    "                    file_pairs.append([filename_1, filename_2])\n",
    "    return file_pairs\n",
    "\n",
    "exchanges = ['bitfinex', 'coinbase_pro', 'hitbtc']\n",
    "get_file_pairs(exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_df(filename):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_ohlcv(df, period='5T'):\n",
    "\n",
    "    # Set date as the index. This is needed for the function to run\n",
    "    df = df.set_index(['date'])\n",
    "\n",
    "    # Aggregation function\n",
    "    ohlc_dict = {                                                                                                             \n",
    "    'open':'first',                                                                                                    \n",
    "    'high':'max',                                                                                                       \n",
    "    'low':'min',                                                                                                        \n",
    "    'close': 'last',                                                                                                    \n",
    "    'base_volume': 'sum'\n",
    "    }\n",
    "\n",
    "    # Apply resampling.\n",
    "    df = df.resample(period, how=ohlc_dict, closed='left', label='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta import add_all_ta_features\n",
    "\n",
    "def fill_nan(df):\n",
    "    \n",
    "    df['close'] = df['close'].ffill()\n",
    "    df = df.bfill(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['closing_time'], unit='s')\n",
    "    df = resample_ohlcv(df)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df['date'] = df['date'].astype('int64')//1e9\n",
    "    df = df.rename(columns={'date': 'closing_time'})\n",
    "        \n",
    "    df['nan_ohlcv'] = df['close'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    df = fill_nan(df)\n",
    "        \n",
    "    df = add_all_ta_features(df, 'open', 'high', 'low', 'close',\n",
    "                             'base_volume', fillna=True)\n",
    "    \n",
    "    df['closing_time'] = df['closing_time'].astype('int64')\n",
    "    df['nan_ohlcv'] = df['nan_ohlcv'].astype('int64')\n",
    "    \n",
    "    df = df.drop(columns=['open', 'high', 'low', 'momentum_kama',\n",
    "                          'momentum_stoch', 'others_cr', 'others_dlr',\n",
    "                          'trend_ema_fast', 'trend_ema_slow', \n",
    "                          'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_kst',\n",
    "                          'trend_macd', 'trend_visual_ichimoku_a',\n",
    "                          'trend_visual_ichimoku_b', 'volatility_bbh',\n",
    "                          'volatility_bbl', 'volatility_bbm',\n",
    "                          'volatility_dch', 'volatility_dcl',\n",
    "                          'volatility_kcc', 'volatility_kch',\n",
    "                          'volatility_kcl'])\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_higher_closing_price(df):\n",
    "    if (df['close_exchange_1'] - df['close_exchange_2']) > 0:\n",
    "        return 'exchange_1'\n",
    "    elif (df['close_exchange_1'] - df['close_exchange_2']) < 0:\n",
    "        return 'exchange_2'\n",
    "    else:\n",
    "        return 'equivalent'\n",
    "\n",
    "def get_pct_higher(df):\n",
    "    if df['higher_closing_price'] == 'exchange_1':\n",
    "        return ((df['close_exchange_1'] / \n",
    "                 df['close_exchange_2'])-1)*100\n",
    "    elif df['higher_closing_price'] == 'exchange_2':\n",
    "        return ((df['close_exchange_2'] / \n",
    "                 df['close_exchange_1'])-1)*100\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_arbitrage_opportunity(df):\n",
    "    if df['pct_higher'] < .55:\n",
    "        return 0 # no arbitrage\n",
    "    elif df['higher_closing_price'] == 'exchange_1':\n",
    "        return -1 # arbitrage exchange 2 to exchange 1\n",
    "    elif df['higher_closing_price'] == 'exchange_2':\n",
    "        return 1 # arbitrage exchange 1 to exchange 2\n",
    "    \n",
    "def get_window_length(df):\n",
    "    target_list = df['arbitrage_opportunity'].to_list()\n",
    "    window_length = 5\n",
    "    window_lengths = []\n",
    "    for i in range(len(target_list)):\n",
    "            if target_list[i] == target_list[i-1]:\n",
    "                window_length += 5\n",
    "                window_lengths.append(window_length)\n",
    "            else:\n",
    "                window_length = 5\n",
    "                window_lengths.append(window_length)      \n",
    "    df['window_length'] = window_lengths\n",
    "    return df\n",
    "        \n",
    "def merge_dfs(df1, df2):\n",
    "    df = pd.merge(df1, df2, on='closing_time',\n",
    "                  suffixes=('_exchange_1', '_exchange_2'))\n",
    "        \n",
    "    df['year'] = pd.to_datetime(df['closing_time'], unit='s').dt.year\n",
    "    df['month'] = pd.to_datetime(df['closing_time'], unit='s').dt.month\n",
    "    df['day'] = pd.to_datetime(df['closing_time'], unit='s').dt.day\n",
    "\n",
    "    df['higher_closing_price'] = df.apply(get_higher_closing_price, axis=1)\n",
    "    df['pct_higher'] = df.apply(get_pct_higher, axis=1)\n",
    "    df['arbitrage_opportunity'] = df.apply(get_arbitrage_opportunity, axis=1)\n",
    "    df = get_window_length(df)\n",
    "    df = df.drop(columns=['higher_closing_price', 'pct_higher'])\n",
    "    df = df[:-8]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "def create_all_arbitrage_csvs(exchanges):\n",
    "    for pair in get_file_pairs(exchanges):\n",
    "        for exchange in exchanges:\n",
    "            if exchange in pair[0]:\n",
    "                exchange_1 = exchange\n",
    "            if exchange in pair[1]:\n",
    "                exchange_2 = exchange\n",
    "        \n",
    "        df1 = get_df('ohlcv_data/' + exchange_1 + '_300/' + pair[0])\n",
    "        print('engineering df1...')\n",
    "        df1 = engineer_features(df1)\n",
    "        print('success!')\n",
    "\n",
    "        df2 = get_df('ohlcv_data/' + exchange_2 + '_300/' + pair[1])\n",
    "        print('engineering df2...')\n",
    "        df2 = engineer_features(df2)\n",
    "        print('success!')\n",
    "\n",
    "        print('merging df1 and df2...')\n",
    "        df = merge_dfs(df1, df2)\n",
    "        print('success!')\n",
    "        \n",
    "        end_of_file_extension = '_' + pair[1].replace('_300', '')\n",
    "        print('saving...')\n",
    "        df.to_csv('arbitrage_data_new/' + exchange_1 + end_of_file_extension)\n",
    "        print('saved ' + exchange_1 + end_of_file_extension + '!')\n",
    "\n",
    "exchanges = ['bitfinex', 'coinbase_pro', 'hitbtc']\n",
    "create_all_arbitrage_csvs(exchanges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
