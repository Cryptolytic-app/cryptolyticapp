{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# the three exchanges we are using...\n",
    "exchanges = ['bitfinex', 'coinbase_pro', 'hitbtc']\n",
    "\n",
    "# function to get pairs of ohlcv csvs from which to create arbitrage data\n",
    "def get_file_pairs(exchanges):\n",
    "    # empty list to fill with filenames of all ohlcv csvs\n",
    "    filenames = []\n",
    "    # i.e., for subdirectory in ohlcv_data directory\n",
    "    for directory in os.listdir('ohlcv_data'):\n",
    "        # .DS_Store files can mess things up, since they aren't directories\n",
    "        if directory != '.DS_Store':\n",
    "            # for each of the files in the subdirectory...\n",
    "            for filename in os.listdir('ohlcv_data/' + directory):\n",
    "                # if the file is a csv...\n",
    "                if filename.endswith('300.csv'):\n",
    "                    # add the filename to the list of filenames\n",
    "                    filenames.append(filename)\n",
    "    # empty list to fill with pairs of csvs from which to make arbitrage data\n",
    "    file_pairs = []\n",
    "    # filename_1, because we will want to compare each filename to another\n",
    "    for filename_1 in filenames:\n",
    "        # these are all the filenames we haven't looped through yet\n",
    "        remaining_filenames = filenames[filenames.index(filename_1)+1:]\n",
    "        # for each of those filenames we haven't looped through yet...\n",
    "        for filename_2 in remaining_filenames:\n",
    "            # exchanges is a list taken as an argument by this function\n",
    "            for exchange in exchanges:\n",
    "                # drop the exchange from the first filename, see if the\n",
    "                # remaining string is contained in the second filename\n",
    "                if filename_1.replace(exchange, '') in filename_2:\n",
    "                    # if so, add the pair of filenames to the list of pairs\n",
    "                    file_pairs.append([filename_1, filename_2])\n",
    "    # return the list of pairs\n",
    "    return file_pairs\n",
    "\n",
    "# getting the list of ohlcv csvs from which to create arbitrage data\n",
    "get_file_pairs(exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# simple function to turn a csv into a dataframe\n",
    "def get_df(filename):\n",
    "    # index_col=0 because csv still has index\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    # returning the dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function resamples ohlcv csvs for a specified candle interval; while \n",
    "# this can be used to change the candle interval for the data, it can also be\n",
    "# used to fill in gaps in the ohlcv data without changing the candle interval\n",
    "def resample_ohlcv(df, period='5T'):\n",
    "    # set the date as the index; this is needed for the function to run\n",
    "    df = df.set_index(['date'])\n",
    "    # dictionary specifying which columns to use for resampling\n",
    "    ohlc_dict = {                                                                                                             \n",
    "    'open':'first',                                                                                                    \n",
    "    'high':'max',                                                                                                       \n",
    "    'low':'min',                                                                                                        \n",
    "    'close': 'last',                                                                                                    \n",
    "    'base_volume': 'sum'\n",
    "    }\n",
    "    # overwriting the df taken as input with a resampled df\n",
    "    df = df.resample(period, how=ohlc_dict, closed='left', label='left')\n",
    "    # returning the resampled df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta import add_all_ta_features\n",
    "\n",
    "# function to handle nans in the data introduced by resampling\n",
    "def fill_nan(df):\n",
    "    # forward filling the closing price where there were gaps in ohlcv csv\n",
    "    df['close'] = df['close'].ffill()\n",
    "    # backfilling the rest of the nans\n",
    "    df = df.bfill(axis=1)\n",
    "    # returning the revised dataframe\n",
    "    return df\n",
    "\n",
    "# function to engineer features that can be engineered pre-merge...\n",
    "def engineer_features(df):\n",
    "    \n",
    "    # turn the closing_time, which is in Unix time, to datetime...\n",
    "    df['date'] = pd.to_datetime(df['closing_time'], unit='s')\n",
    "    # ...which is needed for resampling; resampling fills gaps in data\n",
    "    df = resample_ohlcv(df)\n",
    "    # resetting the index\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # now that df has been resampled, converting back to Unix time...\n",
    "    # dividing by 1e9 to get seconds, not nanoseconds\n",
    "    df['date'] = df['date'].astype('int64')//1e9\n",
    "    # also changing name back to closing_time, to be more precise\n",
    "    df = df.rename(columns={'date': 'closing_time'})\n",
    "    \n",
    "    # adding feature to indicate where rows are just filling gaps in data...\n",
    "    df['nan_ohlcv'] = df['close'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "    # now filling in the nan values in those gap-filling rows...\n",
    "    df = fill_nan(df)\n",
    "    \n",
    "    # adding all the technical analysis features...\n",
    "    df = add_all_ta_features(df, 'open', 'high', 'low', 'close',\n",
    "                             'base_volume', fillna=True)\n",
    "    \n",
    "    # technical analysis library converts some ints to floats; changing back\n",
    "    df['closing_time'] = df['closing_time'].astype('int64')\n",
    "    df['nan_ohlcv'] = df['nan_ohlcv'].astype('int64')\n",
    "    \n",
    "    # dropping features that are highly correlated with other features\n",
    "    df = df.drop(columns=['open', 'high', 'low', 'momentum_kama',\n",
    "                          'momentum_stoch', 'others_cr', 'others_dlr',\n",
    "                          'trend_ema_fast', 'trend_ema_slow', \n",
    "                          'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_kst',\n",
    "                          'trend_macd', 'trend_visual_ichimoku_a',\n",
    "                          'trend_visual_ichimoku_b', 'volatility_bbh',\n",
    "                          'volatility_bbl', 'volatility_bbm',\n",
    "                          'volatility_dch', 'volatility_dcl',\n",
    "                          'volatility_kcc', 'volatility_kch',\n",
    "                          'volatility_kcl'])\n",
    "    \n",
    "    # returning resulting dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following functions are used in engineering features post-merge...\n",
    "\n",
    "# function to create column showing which exchange has a higher closing price\n",
    "def get_higher_closing_price(df):\n",
    "    # i.e., if exchange 1 has the higher closing price...\n",
    "    if (df['close_exchange_1'] - df['close_exchange_2']) > 0:\n",
    "        # return exchange 1\n",
    "        return 'exchange_1'\n",
    "    # otherwise, if exchange 2 has the higher closing price...\n",
    "    elif (df['close_exchange_1'] - df['close_exchange_2']) < 0:\n",
    "        # return exchange 2\n",
    "        return 'exchange_2'\n",
    "    # otherwise, i.e., if neither has a higher closing price...\n",
    "    else:\n",
    "        # return equivalent\n",
    "        return 'equivalent'\n",
    "\n",
    "# function to create column showing percentage by which higher price is higher\n",
    "def get_pct_higher(df):\n",
    "    # i.e., if exchange 1 has a higher closing price than exchange 2...\n",
    "    if df['higher_closing_price'] == 'exchange_1':\n",
    "        # return the percentage by which the exchange 1 closing price is \n",
    "        # greater than the exchange 2 closing price\n",
    "        return ((df['close_exchange_1'] / \n",
    "                 df['close_exchange_2'])-1)*100\n",
    "    # otherwise, if exchange 2 has a higher closing price than exchange 1...\n",
    "    elif df['higher_closing_price'] == 'exchange_2':\n",
    "        # return the percentage by which the exchange 2 closing price is\n",
    "        # greater than the exchange 1 closing price\n",
    "        return ((df['close_exchange_2'] / \n",
    "                 df['close_exchange_1'])-1)*100\n",
    "    # otherwise, i.e., if the closing prices are equivalent...\n",
    "    else:\n",
    "        # return zero\n",
    "        return 0\n",
    "\n",
    "# function to create column showing available arbitrage opportunities\n",
    "def get_arbitrage_opportunity(df):\n",
    "    # assuming the total fees are 0.55%, if the higher closing price is less\n",
    "    # than 0.55% higher than the lower closing price...\n",
    "    if df['pct_higher'] < .55:\n",
    "        # return 0, for no arbitrage\n",
    "        return 0\n",
    "    # otherwise, if the exchange 1 closing price is more than 0.55% higher\n",
    "    # than the exchange 2 closing price...\n",
    "    elif df['higher_closing_price'] == 'exchange_1':\n",
    "        # return -1, for arbitrage from exchange 2 to exchange 1\n",
    "        return -1\n",
    "    # otherwise, if the exchange 2 closing price is more than 0.55% higher\n",
    "    # than the exchange 1 closing price...\n",
    "    elif df['higher_closing_price'] == 'exchange_2':\n",
    "        # return 1, for arbitrage from exchange 1 to exchange 2\n",
    "        return 1\n",
    "    \n",
    "# function to create column showing how long arbitrage opportunity has lasted\n",
    "def get_window_length(df):\n",
    "    # converting arbitrage_opportunity column to a list...\n",
    "    target_list = df['arbitrage_opportunity'].to_list()\n",
    "    # setting initial window length to 5, for 5 minutes; will be updated...\n",
    "    window_length = 5\n",
    "    # creating empty list to fill with values and ultimately convert to column\n",
    "    window_lengths = []\n",
    "    # for i in the range of the length of the arbitrage_opportunity column...\n",
    "    for i in range(len(target_list)):\n",
    "        # if a value in the arbitrage_opportunity column is equal to the\n",
    "        # previous value in the arbitrage_opportunity column...\n",
    "        if target_list[i] == target_list[i-1]:\n",
    "            # increase the window length by five minutes...\n",
    "            window_length += 5\n",
    "            # and append that window length to the list.\n",
    "            window_lengths.append(window_length)\n",
    "        # otherwise, i.e., if a value in the arbitrage_opportunity column is\n",
    "        # not equal to the previous value in the arbitrage_opportunity column\n",
    "        else:\n",
    "            # reset the window length to five minutes...\n",
    "            window_length = 5\n",
    "            # and append that window length to the list\n",
    "            window_lengths.append(window_length)\n",
    "    # convert the window lengths list to a column, showing how long arbitrage\n",
    "    # window / no_arbitrage window has lasted.\n",
    "    df['window_length'] = window_lengths\n",
    "    # return the dataframe with the new window length column\n",
    "    return df\n",
    "        \n",
    "# function to merge dataframes and create final features for arbitrage data\n",
    "def merge_dfs(df1, df2):\n",
    "    # merging two modified ohlcv dfs on closing time to create arbitrage df\n",
    "    df = pd.merge(df1, df2, on='closing_time',\n",
    "                  suffixes=('_exchange_1', '_exchange_2'))\n",
    "    \n",
    "    # feature engineering year, month, and day columns\n",
    "    df['year'] = pd.to_datetime(df['closing_time'], unit='s').dt.year\n",
    "    df['month'] = pd.to_datetime(df['closing_time'], unit='s').dt.month\n",
    "    df['day'] = pd.to_datetime(df['closing_time'], unit='s').dt.day\n",
    "\n",
    "    # getting higher_closing_price feature to create pct_higher feature\n",
    "    df['higher_closing_price'] = df.apply(get_higher_closing_price, axis=1)\n",
    "    # getting pct_higher feature to create arbitrage_opportunity feature\n",
    "    df['pct_higher'] = df.apply(get_pct_higher, axis=1)\n",
    "    # getting arbitrage_opportunity feature\n",
    "    df['arbitrage_opportunity'] = df.apply(get_arbitrage_opportunity, axis=1)\n",
    "    # getting window_length feature\n",
    "    df = get_window_length(df)\n",
    "    # dropping higher_closing_price and pct_higher features, which were\n",
    "    # only needed to feature engineer arbitrage_opportunity and window_length\n",
    "    df = df.drop(columns=['higher_closing_price', 'pct_higher'])\n",
    "    # returning df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the function that creates arbitrage data csvs from ohlcv csvs...\n",
    "def create_all_arbitrage_csvs(exchanges):\n",
    "    # looping through the file pairs used to generate the arbitrage data...\n",
    "    for pair in get_file_pairs(exchanges):\n",
    "        # looping through the specified exchanges...\n",
    "        for exchange in exchanges:\n",
    "            # if one of the specified exchanges is in the first filename...\n",
    "            if exchange in pair[0]:\n",
    "                # that is the first exchange;\n",
    "                exchange_1 = exchange\n",
    "            # if one of the specified exchanges is in the second filename...\n",
    "            if exchange in pair[1]:\n",
    "                # that is the second exchange.\n",
    "                exchange_2 = exchange\n",
    "        \n",
    "        # loading first ohlcv csv in pair...\n",
    "        df1 = get_df('ohlcv_data/' + exchange_1 + '_300/' + pair[0])\n",
    "        # engineering features for first ohlcv csv...\n",
    "        print('engineering df1...')\n",
    "        df1 = engineer_features(df1)\n",
    "        print('success!')\n",
    "\n",
    "        # loading second ohlcv csv in pair...\n",
    "        df2 = get_df('ohlcv_data/' + exchange_2 + '_300/' + pair[1])\n",
    "        # engineering features for second ohlcv csv...\n",
    "        print('engineering df2...')\n",
    "        df2 = engineer_features(df2)\n",
    "        print('success!')\n",
    "\n",
    "        # merging two ohlcv dataframes with their engineered features\n",
    "        print('merging df1 and df2...')\n",
    "        df = merge_dfs(df1, df2)\n",
    "        print('success!')\n",
    "        \n",
    "        # getting the second half of the filename for the csv...\n",
    "        end_of_filename = '_' + pair[1].replace('_300', '')\n",
    "        # assembling whole of the filename for the csv...\n",
    "        filename = exchange_1 + end_of_filename\n",
    "        print('saving...')\n",
    "        # saving csv\n",
    "        df.to_csv('arbitrage_data/' + filename)\n",
    "        print('saved ' + filename + '!')\n",
    "\n",
    "# creating all the arbitrage csvs from the ohlcv data...\n",
    "create_all_arbitrage_csvs(exchanges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
