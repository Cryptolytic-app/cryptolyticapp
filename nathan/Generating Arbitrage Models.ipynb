{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the following is used to create target values from arbitrage data csvs...\n",
    "\n",
    "# specifying arbitrage window length to target, in minutes\n",
    "interval=30\n",
    "\n",
    "# function to get target values; takes df and window length to target\n",
    "def get_target_value(df, interval=interval):\n",
    "    # i.e., if the coming arbitrage window is as long as the targeted interval\n",
    "    if df['window_length_shift'] >= interval:\n",
    "        # then if the coming arbitrage window is for exchange 1 to 2...\n",
    "        if df['arbitrage_opportunity_shift'] == 1:\n",
    "            # return 1, which means arbitrage from exchange 1 to 2\n",
    "            return 1\n",
    "        # otherwise, if the coming arbitrage window is for exchange 2 to 1...\n",
    "        elif df['arbitrage_opportunity_shift'] == -1:\n",
    "            # return -1, which means arbitrage from exchange 2 to 1...\n",
    "            return -1\n",
    "        # otherwise, if we are coming up on no arbitrage opportunity...\n",
    "        elif df['arbitrage_opportunity_shift'] == 0:\n",
    "            # return 0, which means no arbitrage opportunity\n",
    "            return 0\n",
    "    # otherwise, i.e., if the coming window is less than our targeted interval\n",
    "    else:\n",
    "        # return 0, which means no arbitrage opportunity\n",
    "        return 0\n",
    "    \n",
    "# function to create target column\n",
    "def get_target(df, interval=interval):\n",
    "    # used to shift rows; assumes candle length is five minutes, interval is\n",
    "    # in minutes\n",
    "    rows_to_shift = int(-1*(interval/5))\n",
    "    # arbitrage_opportunity feature, shifted by length of targeted interval\n",
    "    df['arbitrage_opportunity_shift'] = df['arbitrage_opportunity'].shift(\n",
    "        rows_to_shift)\n",
    "    # window_length feature, shifted by length of targeted interval\n",
    "    df['window_length_shift'] = df['window_length'].shift(rows_to_shift)\n",
    "    # creating target column; this will indicate if an arbitrage opportunity\n",
    "    # that lasts as long as the targeted interval is forthcoming\n",
    "    df['target'] = df.apply(get_target_value, axis=1)\n",
    "    # dropping unncessary columns, which were only needed to engineer target\n",
    "    df = df.drop(columns=['window_length_shift',\n",
    "                          'arbitrage_opportunity_shift'])\n",
    "    # dropping rows where target could not be calculated due to shift\n",
    "    df = df[:rows_to_shift]\n",
    "    # returning resulting dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions needed to calculate profit...\n",
    "\n",
    "# function to create column showing which exchange has a higher closing price\n",
    "def get_higher_closing_price(df):\n",
    "    # i.e., if exchange 1 has the higher closing price...\n",
    "    if (df['close_exchange_1'] - df['close_exchange_2']) > 0:\n",
    "        # return exchange 1\n",
    "        return 'exchange_1'\n",
    "    # otherwise, if exchange 2 has the higher closing price...\n",
    "    elif (df['close_exchange_1'] - df['close_exchange_2']) < 0:\n",
    "        # return exchange 2\n",
    "        return 'exchange_2'\n",
    "    # otherwise, i.e., if neither has a higher closing price...\n",
    "    else:\n",
    "        # return equivalent\n",
    "        return 'equivalent'\n",
    "        \n",
    "# function to create new features out of closing prices, shifting those\n",
    "# prices by the targeted interval\n",
    "def get_close_shift(df, interval=interval):\n",
    "    rows_to_shift = int(-1*(interval/5))\n",
    "    df['close_exchange_1_shift'] = df['close_exchange_1'].shift(rows_to_shift)\n",
    "    df['close_exchange_2_shift'] = df['close_exchange_2'].shift(rows_to_shift)\n",
    "    return df\n",
    "\n",
    "# function to create profit feature\n",
    "def get_profit(df):\n",
    "    # if exchange 1 has the higher closing price...\n",
    "    if df['higher_closing_price'] == 'exchange_1':\n",
    "        # see how much money you would make if you bought on exchange 2, sold\n",
    "        # on exchange 1, and took account of 0.55% fees\n",
    "        return (((df['close_exchange_1_shift'] / \n",
    "                 df['close_exchange_2'])-1)*100)-.55\n",
    "    # otherwise, if exchange 2 has the higher closing price...\n",
    "    elif df['higher_closing_price'] == 'exchange_2':\n",
    "        # see how much money you would make if you bought on exchange 1, sold\n",
    "        # on exchange 2, and took account of 0.55% fees\n",
    "        return (((df['close_exchange_2_shift'] / \n",
    "                 df['close_exchange_1'])-1)*100)-.55\n",
    "    # otherwise, i.e., if the closing prices are the same...\n",
    "    else:\n",
    "        # return zero, because in that case you shouldn't make a trade\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_all_arbitrage_models():\n",
    "    # for each of the files in the arbitrage_data directory\n",
    "    for filename in os.listdir('arbitrage_data'):\n",
    "        # if the file is a csv...\n",
    "        if filename.endswith('.csv'):\n",
    "            # getting the filename for the eventual model...\n",
    "            model_name = filename.replace('.csv', '_rfc')\n",
    "            print(model_name.upper())\n",
    "            # loading arbitrage data csv\n",
    "            df = pd.read_csv('arbitrage_data/' + filename, index_col=0)\n",
    "\n",
    "        # getting the target feature\n",
    "        df = get_target(df)\n",
    "        \n",
    "        # where to split df for 70/30 test/train split...\n",
    "        test_train_split_row = round(len(df)*.7)\n",
    "        # getting closing time for row at which test/train split is made...\n",
    "        test_train_split_time = df['closing_time'][test_train_split_row]\n",
    "\n",
    "        # subtracting one week from that closing time for training data...\n",
    "        train_cutoff_time = test_train_split_time - 604800\n",
    "        # adding one week to that closing time for test data...\n",
    "        test_cutoff_time = test_train_split_time + 604800\n",
    "        # used to ensure we have a two week gap between test and train data\n",
    "        \n",
    "        # training set will end one week before the 7/10th row in dataframe\n",
    "        train = df[df['closing_time'] < train_cutoff_time]\n",
    "        # test set will begin one week after the 7/10th row in dataframe\n",
    "        test = df[df['closing_time'] > test_cutoff_time]\n",
    "        # printing shapes to track progress\n",
    "        print('train and test shape:'.format(model=model_name), \n",
    "              train.shape, test.shape)\n",
    "\n",
    "        # model uses all features; only dropping target\n",
    "        features = df.drop(columns=['target']).columns.tolist()\n",
    "        # specifying name of target column\n",
    "        target = 'target'\n",
    "\n",
    "        # separating features from target\n",
    "        X_train = train[features]\n",
    "        X_test = test[features]\n",
    "        y_train = train[target]\n",
    "        y_test = test[target]\n",
    "        \n",
    "        # defining model\n",
    "        model = RandomForestClassifier(max_depth=75, n_estimators=100, \n",
    "                                       n_jobs=-1, random_state=42)\n",
    "        \n",
    "        # i.e., provided we have enough data to train on...\n",
    "        if X_train.shape[0] > 1000:\n",
    "            # fitting the model...\n",
    "            model.fit(X_train, y_train)\n",
    "            print('model fitted!')\n",
    "            # getting accuracy score for train set...\n",
    "            train_score = model.score(X_train, y_train)\n",
    "            print('train accuracy:', train_score)\n",
    "            # making predictions...\n",
    "            y_preds = model.predict(X_test)\n",
    "            print('predictions made!')\n",
    "            # getting accuracy score for test set...\n",
    "            score = accuracy_score(y_test, y_preds)\n",
    "            print('test accuracy:', score)\n",
    "\n",
    "            # saving the model...\n",
    "            pickle.dump(model, open('pickles/{model}.pkl'.format(\n",
    "                model=model_name), 'wb'))\n",
    "            print('pickle saved!'.format(model=model) + '\\n')\n",
    "                \n",
    "            # getting labels for confusion matrix...\n",
    "            unique_y_test = y_test.unique().tolist()\n",
    "            unique_y_preds = list(set(y_preds))\n",
    "            labels = list(set(unique_y_test + unique_y_preds))\n",
    "            labels.sort()\n",
    "            columns = [f'Predicted {label}' for label in labels]\n",
    "            index = [f'Actual {label}'  for label in labels]\n",
    "            # creating and printing confusion matrix...\n",
    "            confusion = pd.DataFrame(confusion_matrix(y_test, y_preds),\n",
    "                                     columns=columns, index=index)\n",
    "            print(model_name + ' confusion matrix:')\n",
    "            print(confusion, '\\n')\n",
    "                \n",
    "            # creating dataframe from test set to calculate profitability\n",
    "            test_with_preds = X_test\n",
    "            # adding column with higher closing price...\n",
    "            test_with_preds['higher_closing_price'\n",
    "                           ] = test_with_preds.apply(\n",
    "                get_higher_closing_price, axis=1)\n",
    "            # adding column with shifted closing prices...\n",
    "            test_with_preds = get_close_shift(test_with_preds)\n",
    "            # adding column with predictions\n",
    "            test_with_preds['pred'] = y_preds\n",
    "            # adding column with profitability of predictions\n",
    "            test_with_preds['pct_profit'] = test_with_preds.apply(\n",
    "                get_profit, axis=1).shift(-1)\n",
    "            # filtering out rows where no arbitrage is predicted\n",
    "            test_with_preds = test_with_preds[test_with_preds['pred'] != 0]\n",
    "            # calculating mean profit where arbitrage predicted...\n",
    "            pct_profit_mean = test_with_preds['pct_profit'].mean()\n",
    "            # calculating median profit where arbitrage predicted...\n",
    "            pct_profit_median = test_with_preds['pct_profit'].median()\n",
    "            print('percent profit mean:', pct_profit_mean)\n",
    "            print('percent profit median:', pct_profit_median, '\\n\\n')\n",
    "\n",
    "        # i.e., if there are less than 1000 rows on which to train...\n",
    "        else:\n",
    "            print('not enough data!'.format(model=model_name))\n",
    "\n",
    "# creating all the arbitrage models from the arbitrage data csvs...\n",
    "create_all_arbitrage_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
