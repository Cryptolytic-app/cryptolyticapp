{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the following is used to create target values from arbitrage data csvs...\n",
    "\n",
    "# specifying arbitrage window length to target, in minutes\n",
    "interval=30\n",
    "\n",
    "# function to get target values; takes df and window length to target\n",
    "def get_target_value(df, interval=interval):\n",
    "    # i.e., if the coming arbitrage window is as long as the targeted interval\n",
    "    if df['window_length_shift'] >= interval:\n",
    "        # then if the coming arbitrage window is for exchange 1 to 2...\n",
    "        if df['arbitrage_opportunity_shift'] == 1:\n",
    "            # return 1, which means arbitrage from exchange 1 to 2\n",
    "            return 1\n",
    "        # otherwise, if the coming arbitrage window is for exchange 2 to 1...\n",
    "        elif df['arbitrage_opportunity_shift'] == -1:\n",
    "            # return -1, which means arbitrage from exchange 2 to 1...\n",
    "            return -1\n",
    "        # otherwise, if we are coming up on no arbitrage opportunity...\n",
    "        elif df['arbitrage_opportunity_shift'] == 0:\n",
    "            # return 0, which means no arbitrage opportunity\n",
    "            return 0\n",
    "    # otherwise, i.e., if the coming window is less than our targeted interval\n",
    "    else:\n",
    "        # return 0, which means no arbitrage opportunity\n",
    "        return 0\n",
    "    \n",
    "# function to create target column\n",
    "def get_target(df, interval=interval):\n",
    "    # used to shift rows; assumes candle length is five minutes, interval is\n",
    "    # in minutes\n",
    "    rows_to_shift = int(-1*(interval/5))\n",
    "    # arbitrage_opportunity feature, shifted by length of targeted interval,\n",
    "    # minus one to predict ten minutes in advance rather than five\n",
    "    df['arbitrage_opportunity_shift'] = df['arbitrage_opportunity'].shift(\n",
    "        rows_to_shift - 1)\n",
    "    # window_length feature, shifted by length of targeted interval, minus one\n",
    "    # to predict ten minutes in advance rather than five\n",
    "    df['window_length_shift'] = df['window_length'].shift(rows_to_shift - 1)\n",
    "    # creating target column; this will indicate if an arbitrage opportunity\n",
    "    # that lasts as long as the targeted interval is forthcoming\n",
    "    df['target'] = df.apply(get_target_value, axis=1)\n",
    "    # dropping rows where target could not be calculated due to shift\n",
    "    df = df[:rows_to_shift - 1]\n",
    "    # returning resulting dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions needed to calculate profit...\n",
    "\n",
    "# function to create column showing which exchange has a higher closing price\n",
    "def get_higher_closing_price(df):\n",
    "    # i.e., if exchange 1 has the higher closing price...\n",
    "    if (df['close_exchange_1'] - df['close_exchange_2']) > 0:\n",
    "        # return exchange 1\n",
    "        return 1\n",
    "    # otherwise, if exchange 2 has the higher closing price...\n",
    "    elif (df['close_exchange_1'] - df['close_exchange_2']) < 0:\n",
    "        # return exchange 2\n",
    "        return 2\n",
    "    # otherwise, i.e., if neither has a higher closing price...\n",
    "    else:\n",
    "        # return equivalent\n",
    "        return 0\n",
    "        \n",
    "# function to create new columns that align selling prices with buying prices,\n",
    "# assuming that the sale takes place exactly one arbitrage window length\n",
    "# after the purchase; if the specified arbitrage window length is 30 minutes,\n",
    "# (six rows), we want to shift by -5 (five rows up) so that the sixth row\n",
    "# aligns with the first, so we want to add one to rows_to_shift (-6 + 1 = -5)\n",
    "def get_close_shift(df, interval=interval):\n",
    "    rows_to_shift = int(-1*(interval/5))\n",
    "    df['close_exchange_1_shift'] = df['close_exchange_1'].shift(\n",
    "        rows_to_shift + 1)\n",
    "    df['close_exchange_2_shift'] = df['close_exchange_2'].shift(\n",
    "        rows_to_shift + 1)\n",
    "    return df\n",
    "\n",
    "# function to create profit feature\n",
    "def get_profit(df):\n",
    "    # if exchange 1 has the higher closing price...\n",
    "    if df['higher_closing_price'] == 1:\n",
    "        # see how much money you would make if you bought on exchange 2, sold\n",
    "        # on exchange 1, and took account of 0.55% fees\n",
    "        return (((df['close_exchange_1_shift'] / \n",
    "                 df['close_exchange_2'])-1)*100)-.55\n",
    "    # otherwise, if exchange 2 has the higher closing price...\n",
    "    elif df['higher_closing_price'] == 2:\n",
    "        # see how much money you would make if you bought on exchange 1, sold\n",
    "        # on exchange 2, and took account of 0.55% fees\n",
    "        return (((df['close_exchange_2_shift'] / \n",
    "                 df['close_exchange_1'])-1)*100)-.55\n",
    "    # otherwise, i.e., if the closing prices are the same...\n",
    "    else:\n",
    "        # return zero, because in that case you shouldn't make a trade\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BITFINEX_HITBTC_EOS_USDT\n",
      "train and test shape: (39565, 101) (15804, 101)\n",
      "model fitted!\n",
      "train accuracy: 1.0\n",
      "predictions made!\n",
      "test accuracy: 0.9512148823082763\n",
      "pickle saved!\n",
      "\n",
      "bitfinex_hitbtc_eos_usdt confusion matrix:\n",
      "           Predicted -1  Predicted 0  Predicted 1\n",
      "Actual -1             0          375            0\n",
      "Actual 0              0        14971           36\n",
      "Actual 1              0          360           62 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanvanwyck/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/nathanvanwyck/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/nathanvanwyck/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/nathanvanwyck/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/nathanvanwyck/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent profit mean: 0.5749495619042414\n",
      "percent profit median: 0.5468538114283887 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_all_arbitrage_models():\n",
    "    # for each of the files in the arbitrage_data directory\n",
    "    for filename in os.listdir('arbitrage_data'):\n",
    "        # if the file is a csv...\n",
    "        if filename.endswith('.csv'):\n",
    "            # getting the filename for the eventual model...\n",
    "            model_name = filename.replace('.csv', '')\n",
    "            print(model_name.upper())\n",
    "            # loading arbitrage data csv\n",
    "            df = pd.read_csv('arbitrage_data/' + filename, index_col=0)\n",
    "\n",
    "            # getting the target feature\n",
    "            df = get_target(df)\n",
    "\n",
    "            # where to split df for 70/30 test/train split...\n",
    "            test_train_split_row = round(len(df)*.7)\n",
    "            # getting closing time for row at which test/train split is made\n",
    "            test_train_split_time = df['closing_time'][test_train_split_row]\n",
    "\n",
    "            # subtracting one week from that closing time for training data...\n",
    "            train_cutoff_time = test_train_split_time - 604800\n",
    "            # adding one week to that closing time for test data...\n",
    "            test_cutoff_time = test_train_split_time + 604800\n",
    "            # used to ensure we have two week gap between test and train data\n",
    "\n",
    "            # training set ends one week before the 7/10th row in dataframe\n",
    "            train = df[df['closing_time'] < train_cutoff_time]\n",
    "            # test set begins one week after the 7/10th row in dataframe\n",
    "            test = df[df['closing_time'] > test_cutoff_time]\n",
    "            # printing shapes to track progress\n",
    "            print('train and test shape:'.format(model=model_name), \n",
    "                  train.shape, test.shape)\n",
    "\n",
    "            # specifying features for model to use; not using open, high, or\n",
    "            # low, which are highly correlated with close and do not improve\n",
    "            # model performance\n",
    "            features = ['closing_time', 'close_exchange_1',\n",
    "                    'base_volume_exchange_1', 'nan_ohlcv_exchange_1',\n",
    "                    'volume_adi_exchange_1', 'volume_obv_exchange_1',\n",
    "                    'volume_cmf_exchange_1', 'volume_fi_exchange_1',\n",
    "                    'volume_em_exchange_1', 'volume_vpt_exchange_1',\n",
    "                    'volume_nvi_exchange_1', 'volatility_atr_exchange_1',\n",
    "                    'volatility_bbhi_exchange_1', \n",
    "                    'volatility_bbli_exchange_1', \n",
    "                    'volatility_kchi_exchange_1', \n",
    "                    'volatility_kcli_exchange_1',\n",
    "                    'volatility_dchi_exchange_1',\n",
    "                    'volatility_dcli_exchange_1',\n",
    "                    'trend_macd_signal_exchange_1', \n",
    "                    'trend_macd_diff_exchange_1', 'trend_adx_exchange_1',\n",
    "                    'trend_adx_pos_exchange_1', 'trend_adx_neg_exchange_1',\n",
    "                    'trend_vortex_ind_pos_exchange_1', \n",
    "                    'trend_vortex_ind_neg_exchange_1', \n",
    "                    'trend_vortex_diff_exchange_1', 'trend_trix_exchange_1',\n",
    "                    'trend_mass_index_exchange_1', 'trend_cci_exchange_1',\n",
    "                    'trend_dpo_exchange_1', 'trend_kst_sig_exchange_1',\n",
    "                    'trend_kst_diff_exchange_1', 'trend_aroon_up_exchange_1',\n",
    "                    'trend_aroon_down_exchange_1',\n",
    "                    'trend_aroon_ind_exchange_1',\n",
    "                    'momentum_rsi_exchange_1', 'momentum_mfi_exchange_1',\n",
    "                    'momentum_tsi_exchange_1', 'momentum_uo_exchange_1',\n",
    "                    'momentum_stoch_signal_exchange_1',\n",
    "                    'momentum_wr_exchange_1', 'momentum_ao_exchange_1',\n",
    "                    'others_dr_exchange_1', 'close_exchange_2',\n",
    "                    'base_volume_exchange_2', 'nan_ohlcv_exchange_2',\n",
    "                    'volume_adi_exchange_2', 'volume_obv_exchange_2',\n",
    "                    'volume_cmf_exchange_2', 'volume_fi_exchange_2',\n",
    "                    'volume_em_exchange_2', 'volume_vpt_exchange_2',\n",
    "                    'volume_nvi_exchange_2', 'volatility_atr_exchange_2',\n",
    "                    'volatility_bbhi_exchange_2', \n",
    "                    'volatility_bbli_exchange_2',\n",
    "                    'volatility_kchi_exchange_2',\n",
    "                    'volatility_kcli_exchange_2',\n",
    "                    'volatility_dchi_exchange_2',\n",
    "                    'volatility_dcli_exchange_2',\n",
    "                    'trend_macd_signal_exchange_2',\n",
    "                    'trend_macd_diff_exchange_2', 'trend_adx_exchange_2',\n",
    "                    'trend_adx_pos_exchange_2', 'trend_adx_neg_exchange_2',\n",
    "                    'trend_vortex_ind_pos_exchange_2',\n",
    "                    'trend_vortex_ind_neg_exchange_2',\n",
    "                    'trend_vortex_diff_exchange_2', 'trend_trix_exchange_2',\n",
    "                    'trend_mass_index_exchange_2', 'trend_cci_exchange_2',\n",
    "                    'trend_dpo_exchange_2', 'trend_kst_sig_exchange_2',\n",
    "                    'trend_kst_diff_exchange_2', 'trend_aroon_up_exchange_2',\n",
    "                    'trend_aroon_down_exchange_2',\n",
    "                    'trend_aroon_ind_exchange_2',\n",
    "                    'momentum_rsi_exchange_2', 'momentum_mfi_exchange_2',\n",
    "                    'momentum_tsi_exchange_2', 'momentum_uo_exchange_2',\n",
    "                    'momentum_stoch_signal_exchange_2',\n",
    "                    'momentum_wr_exchange_2', 'momentum_ao_exchange_2',\n",
    "                    'others_dr_exchange_2', 'year', 'month', 'day',\n",
    "                    'higher_closing_price', 'pct_higher', \n",
    "                    'arbitrage_opportunity', 'window_length']\n",
    "            # specifying name of target column\n",
    "            target = 'target'\n",
    "\n",
    "            # separating features from target\n",
    "            X_train = train[features]\n",
    "            X_test = test[features]\n",
    "            y_train = train[target]\n",
    "            y_test = test[target]\n",
    "\n",
    "            # defining model\n",
    "            model = RandomForestClassifier(max_depth=75, n_estimators=100, \n",
    "                                           n_jobs=-1, random_state=42)\n",
    "\n",
    "            # i.e., provided we have enough data to train on, and for testing\n",
    "            if (X_train.shape[0] > 1000) and (X_test.shape[0] > 0):\n",
    "                # fitting the model...\n",
    "                model.fit(X_train, y_train)\n",
    "                print('model fitted!')\n",
    "                # getting accuracy score for train set...\n",
    "                train_score = model.score(X_train, y_train)\n",
    "                print('train accuracy:', train_score)\n",
    "                # making predictions...\n",
    "                y_preds = model.predict(X_test)\n",
    "                print('predictions made!')\n",
    "                # getting accuracy score for test set...\n",
    "                score = accuracy_score(y_test, y_preds)\n",
    "                print('test accuracy:', score)\n",
    "\n",
    "                # saving the model...\n",
    "                pickle.dump(model, open('pickles/{model}.pkl'.format(\n",
    "                    model=model_name), 'wb'))\n",
    "                print('pickle saved!'.format(model=model) + '\\n')\n",
    "\n",
    "                # getting labels for confusion matrix...\n",
    "                unique_y_test = y_test.unique().tolist()\n",
    "                unique_y_preds = list(set(y_preds))\n",
    "                labels = list(set(unique_y_test + unique_y_preds))\n",
    "                labels.sort()\n",
    "                columns = [f'Predicted {label}' for label in labels]\n",
    "                index = [f'Actual {label}'  for label in labels]\n",
    "                # creating and printing confusion matrix...\n",
    "                confusion = pd.DataFrame(confusion_matrix(y_test, y_preds),\n",
    "                                         columns=columns, index=index)\n",
    "                print(model_name + ' confusion matrix:')\n",
    "                print(confusion, '\\n')\n",
    "\n",
    "                # creating dataframe from test set to calculate profitability\n",
    "                test_with_preds = X_test\n",
    "                # adding column with higher closing price...\n",
    "                test_with_preds['higher_closing_price'\n",
    "                               ] = test_with_preds.apply(\n",
    "                    get_higher_closing_price, axis=1)\n",
    "                # adding column with shifted closing prices...\n",
    "                test_with_preds = get_close_shift(test_with_preds)\n",
    "                # adding column with predictions\n",
    "                test_with_preds['pred'] = y_preds\n",
    "                # adding column with profitability of arbitrage; shifting by\n",
    "                # negative two so it is aligned with predictions, which are\n",
    "                # ten minutes (two candles) in advance of the arbitrage\n",
    "                test_with_preds['pct_profit'] = test_with_preds.apply(\n",
    "                    get_profit, axis=1).shift(-2)\n",
    "                # filtering out rows where no arbitrage is predicted\n",
    "                test_with_preds = test_with_preds[\n",
    "                    test_with_preds['pred'] != 0]\n",
    "                # calculating mean profit where arbitrage predicted...\n",
    "                pct_profit_mean = test_with_preds['pct_profit'].mean()\n",
    "                # calculating median profit where arbitrage predicted...\n",
    "                pct_profit_median = test_with_preds['pct_profit'].median()\n",
    "                print('percent profit mean:', pct_profit_mean)\n",
    "                print('percent profit median:', pct_profit_median, '\\n\\n')\n",
    "\n",
    "            # i.e., if there are less than 1000 rows on which to train...\n",
    "            else:\n",
    "                print('not enough data!'.format(model=model_name))\n",
    "\n",
    "# creating all the arbitrage models from the arbitrage data csvs...\n",
    "create_all_arbitrage_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
